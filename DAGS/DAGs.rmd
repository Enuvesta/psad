---
title: "Intro to causal inference"
output:
  html_document: default
  html_notebook: default
---


### ''I would rather discover one causal relation than be King of Persia.''  Democritus 



# Confounder in simple linear regression



Смоделируем зависимости, указанные на втором графе (Fork). Заметим, что здесь есть только одна переменная, которая является экзогенной (Z), то есть она не зависит ни от какой другой переменной в системе (не зависит от X, Y, эндогенных переменных).

1. Сгенерируйте `Z` - большую (N = 100000) выборку из нормального распределения. Сгенерируйте также `X = 0.5 * Z + Norm(0,1)` и `Y = 0.3 * Z + 0.4 * X + Norm(1,0)`. Сделайте две регрессии `Y ~ X, Y ~ Z + X`.  Что можно сказать о 95% доверительном интервале (`confint`) на коэффициент регрессии перед `X` в двух этих моделях? Почему так происходит? Какую модель вы бы выбрали, если перед вами стояла бы задача точного прогнозирования ? интерпретации модели? 

```{r}
Z = rnorm(100000, 0, 1)
X = 0.5 * Z + rnorm(100000,0,1)
Y = 0.3 * Z + 0.4 * X + rnorm(100000,0,1)
m1 <- lm(Y ~ X)
m2 <- lm(Y ~ Z + X) #fork
summary(m1)
summary(m2)
confint(m1)
confint(m2)
```
Вторую, т.к. ДИ для X во второй модели совпадает с тем, как мы генерировали данные. Данный случай -- вилка. 


2. Теперь рассмотрим первую картинку (Collider). Cгенерируйте выборку того же размера `N` согласно выражениям `X = Norm(1,0)`, `Y = 0.7 * X + Norm(1,0)`, `Z=1.2 * X + 0.6 * Y`. Какая модель лучше предсказывает отклик? Какую модель вы бы выбрали для интерпретации зависимостей?  


```{r}
X = rnorm(100000,0,1)
Y = 0.7 * X + rnorm(100000,0,1)
Z = 1.2 * X + 0.6 * Y
m3 <- lm(Y ~ X)
m4 <- lm(Y ~ Z + X)
summary(m3)
summary(m4)
confint(m3)
confint(m4)
```
Первую, т.к. ДИ для X во второй модели совпадает с тем, как мы генерировали данные. Данный случай -- коллайдер.






#  DAG's


В этой части задания мы познакомимся с простейшим анализом ациклических графов с помощью автоматических методов, который может быть полезен, когда в вашей системе миллоны вершин и подход "с ручкой и бумагой" прекращает вызывать бурный восторг.

```{r}
library("dagitty")
library("lavaan")
```


Зададим ациклический направленный граф следующим образом
```{r}
g1 <- dagitty('dag {
    X [pos="0,1"]
    Y [pos="1,1"]
    Z [pos="2,1"]
    W [pos="1,0"]
    T [pos="2,2"]
    
    X -> Y -> Z -> T
    X -> W -> Y -> T
    W -> Z
}')
plot(dagitty:::graphLayout(g1)) # auto plot
plot(g1) # use hand crafted coordinates
```

1. Возьмем определенную вершину, скажем `Z`. Чем отличаются вывод функции `parents(g, "Z")` от `ancestors(g, "Z")`? Аналогичный вопрос для `children(), descendants()`?
```{r}
parents(g1, "Z")
ancestors(g1, "Z")
children(g1, "Z")
descendants(g1, "Z")
```
Родитель -- непосредственно вершина из которой идет стрелка (путь -- 1 ребро), предки -- вершины, из которых можно попасть в данную. Аналогично для детей и потомков.

2. В данном графе всего 5 вершин. Можете ли вы назвать все ненаправленные пути, которые ведут из вершины `X` в вершину `T`? Можете ли вы ответить на тот же вопрос но только для направленных путей? Проверьте себя с помощью функции `paths(..., directed = True)`, которая заодно поможет вам ответить на вопрос о том, какие из этих путей открыты? Достаточно ли этой информации для того, чтобы ответить на вопрос о d-разделимости этих вершин?

```{r}
paths(g1, from = "X", to = "T", directed = FALSE)
paths(g1, from = "X", to = "T", directed = TRUE)
```

3. Еще раз взгляните на граф `g1`. Для этого графа перечислите все возможные пары несмежных вершин и для каждой такой пары укажите множество вершин, по которым нужно взять условие, чтобы рассматриваемая пара вершин была условно независимой. Проверьте свои догадки с помощью функции `impliedConditionalIndependencies`.  

```{r}
impliedConditionalIndependencies(g1)
```



4. Пусть есть граф `g2`, представленный на рисунке ниже. Вы строите линейную регрссию вида `Y=a+bX+cZ`. Какие переменые (-ая) могут быть подставлены в эту модель в качестве `Z`, чтобы оценка X в модели регрессии (коэффициент `b`) был равен нулю? Как вам в этом может помочь функция `dseparated`? 

```{r, echo=F}
g2 <- dagitty("dag {
    X -> R -> S -> T <- U <- V -> Y
}")
plot(dagitty:::graphLayout(g2))
```


```{r}
dseparated(g2, "X", "Y", "R")
dseparated(g2, "X", "Y", "S")
dseparated(g2, "X", "Y", "T")
dseparated(g2, "X", "Y", "V")
dseparated(g2, "X", "Y", "U")
#confint(lm(Y ~ X + T , data=simulateSEM(g2, N = 100000)))
```
Не должно быть коллайдеров между X и Y, чтобы коэффициент был отличен от нуля. Соответственно, это вершина T.

5. Пусть есть граф `g3`. Вы строите линейную регрессионную модель согласно формуле `Y=a+bX+cR+dS+eT+fP` на данных, которые были сгенерированы согласно зависимостям, представленным в виде графа `g3`. Какие коэффициенты (`a,b,c,d,e,f`) вы ожидаете увидеть нулевыми? Почему? 
Проверить ответ на этот вопрос можно следующим образом. Cгенерируйте выборку по графу `g3` с помощью функции `simulateSEM` (положив аргумент `N = 100000`). После чего постройте предложенную регрессионную модель и получите доверительнй интервал на оценненные коэффициенты в линейной регрессионной модели (`confint`). Результаты, полученные симуляционным путем нужно объяснить. 

```{r}
g3 <- dagitty("dag {
    X -> R -> S -> T <- U <- V -> Y
    T -> P
}")
plot( dagitty:::graphLayout(g3) )
vars <- c("X","R","S","T","P")
intersect( vars, dseparated(g3, "Y", list(), vars) )
```

Ожидаются нули при "X", "R" и "P"
```{r}
confint(lm(Y ~ X + R + S + T + P, data=simulateSEM(g3, N = 100000)))
```

 
 


6.  Для каждой вершины графа `g4`, представленного ниже, получите минимальный набор вершин, по которым нужно обусловиться, чтобы рассматриваемая веришина была независимa от всех остальных вершин в графе. Данный набор в англоязычной литературе называется `markovBlanket`. Также называется и функция, которая вам в этом может помочь.  

```{r}
g4 <- dagitty("dag { 
X <- Z1 -> Z3 <- Z2 -> Y
X <- Z3 -> Y
X -> W -> Y
}")
plot(dagitty:::graphLayout(g4))
```

```{r}
vars <- c("X","Y","Z1","Z2","Z3", "W")
for(v in vars){
    cat(v, ":", markovBlanket(g4, v), "\n")
}
```



7. На каких ребрах в графах `g1, g4` можно изменить направление так, чтобы по данным нельзя было построить статистическую процедуру провреки отличия нового графа от исходного (с помощью d-разделимости)? Подсказка: можно изменять направление любых стрелок, которые не изменяют множество коллайдеров (v-образных структур) и не добавляют циклов. Проверить свой ответ можно с помощью функции `equivalenceClass`.

```{r}
plot(dagitty:::graphLayout(equivalenceClass(g1)))
plot(dagitty:::graphLayout(equivalenceClass(g4)))
```

Видим, что в графе `g1` можно поменять направление всех ребер, а в графе `g4` ни одного.


8. Пусть у вас есть граф `g5` и вы хотите оценить причинно-следственное влияние `X` на `Y`. Для этого вам нужно найти хотя бы одно множество вершин, которое удовлетворяет условию "задней двери" (определение см. в лекции). Найдите хотя бы одно такое множество и проверьте правильность своего ответа с помощью функции `isAdjustmentSet`,  в которой положите `exposure = "X", outcome = "Y"`. 


```{r}
g5 <-  dagitty('dag {
A -> X
B -> A
B -> Z
C -> D
C -> Z
D -> Y
W -> Y
X -> W
Z -> X
Z -> Y
}')
plot(dagitty:::graphLayout(g5))
```

```{r}
adjustmentSets(g5, exposure = "X", outcome = "Y", type="all")
```




# Еще один небольшой парадокс  

В одной из  больших организаций есть две столовые. Утверждается, что обе они готовят здоровую пищу и между ними нет разницы в смысле калорийности пищи. При этом руководство компании заинтересовано в том, чтобы сотрудники были здоровы и поэтому они наняли двух статистиков, которым поручили проанализировать прирост веса за год только для тех людей, которые на протяжении года питались только в одной столовой. 

Первый статистик утверждает, что раз мы хотим анализировать прирост веса людей, давайте воспользуемся критерием стьюдента, проверяющим, что среднее в двух группах не отличается и применим этот критерий к попарным разностям веса (конечный вес - начальный вес) внутри каждой группы.

Второй говорит, что смотреть нужно не на прирост веса, а на изменение веса в группах, которые определяются одинаковым начальным весом людей. То есть разбить множество начальных весов на некоторые небольшие интервалы и посмотреть на разницу средних весов людей после года питания в каждой из столовй, после чего применить любой статистистический тест к таким разностям. (anova?)

1. Вам нужно ответить на вопрос, какой из этиx подходов лучше. Прежде чем ответить, какой из подходов лучше, сначала вам нужно получить результаты каждого из подходов.

2. Далее, нарисуйте граф. модель, соответствующую задаче, в которую включите такие вершины как  начальный вес, конечнный вес, выбор столовой, прирост веса за год.

3. Аргументированно защитите оба подхода / докажите, что один (оба) из этих подходов не верны. 


```{r}
library(data.table)
dt <-  data.table(read.csv("weight.csv", row.names = NULL))
d1 <- dt[dt$group == 1]$final_weight - dt[dt$group == 1]$initial_weight
d0 <- dt[dt$group == 0]$final_weight - dt[dt$group == 0]$initial_weight
t.test(d1, d0)$p.value
```
Тест Стьюдента не отвергает гипотезу о равенстве среднего.

```{r}
w <- dt$initial_weight
hist(w, breaks=5, col='grey')
```

Выделим 4 группы по весу:

* От 40 до 60
* От 60 до 80
* От 80 до 100
* От 100 до 120

```{r}
w_40_60 = dt[(dt$initial_weight >= 40) & (dt$initial_weight < 60)]

w_60_80 = dt[(dt$initial_weight >= 60) & (dt$initial_weight < 80)]

w_80_100 = dt[(dt$initial_weight >= 80) & (dt$initial_weight < 100)]

w_100_120 = dt[(dt$initial_weight >= 100) & (dt$initial_weight <= 120)]

w_40_60_0 = w_40_60[w_40_60$group == 0]$final_weight - w_40_60[w_40_60$group == 0]$initial_weight
w_40_60_1 = w_40_60[w_40_60$group == 1]$final_weight - w_40_60[w_40_60$group == 1]$initial_weight

w_60_80_0 = w_60_80[w_60_80$group == 0]$final_weight - w_60_80[w_60_80$group == 0]$initial_weight
w_60_80_1 = w_60_80[w_60_80$group == 1]$final_weight - w_60_80[w_60_80$group == 1]$initial_weight

w_80_100_0 = w_80_100[w_80_100$group == 0]$final_weight - w_80_100[w_80_100$group == 0]$initial_weight
w_80_100_1 = w_80_100[w_80_100$group == 1]$final_weight - w_80_100[w_80_100$group == 1]$initial_weight

w_100_120_0 = w_100_120[w_100_120$group == 0]$final_weight - w_100_120[w_100_120$group == 0]$initial_weight
w_100_120_1 = w_100_120[w_100_120$group == 1]$final_weight - w_100_120[w_100_120$group == 1]$initial_weight

```

Посчитаем средние:

```{r}
mean0 <- c(mean(w_40_60_0), mean(w_60_80_0), mean(w_80_100_0), mean(w_100_120_0))
mean1 <- c(mean(w_40_60_1), mean(w_60_80_1), mean(w_80_100_1), mean(w_100_120_1))
wilcox.test(mean0, mean1, paired = TRUE)
```
Критерий Уилкоксона для связанных выборок тоже не отвергает гипотезу о равенстве средних.

```{r}
weight_graph <-  dagitty('dag {
Initial_Weight -> Change
Change -> Final_Weight
Eatery -> Change
}')
plot(dagitty:::graphLayout(weight_graph))
```

# Пример оценки графа зависимостей по данным.

Существует ряд алгоритмов для того, чтобы оценивать граф зависимостей по реальным данным. Вот некоторые из них: 
* PC (Spirtes et al. 2000)
* FCI (Spirtes et al. 2000, 1999a)
* RFCI (Colombo et al. 2012)  
* GES (Chickering 2002) 
* GIES (Hauser and Buhlmann 2012)
* IDA (Maathuis et al. 2009) 


Вот, например один из этих алгоритмов. Граф слева обозначает истинный граф зависимостей в данных. Граф справа - его оценку. 
```{r}
#library("pcalg")
#data("gmG")
#suffStat <- list(C = cor(gmG8$x), n = nrow(gmG8$x))
#pc.gmG <- pc(suffStat, indepTest = gaussCItest,
#p = ncol(gmG8$x), alpha = 0.01)
#stopifnot(require(Rgraphviz)) # needed for graph plot
#par(mfrow = c(1,2))
#plot(gmG8$g, main = "") ; 
#plot(pc.gmG, main = "")
```


Если вам придется делать оценку такого графа для промышленной задачи, посмотрите также в сторону такой библиотеки, как `causaleffect`. 















